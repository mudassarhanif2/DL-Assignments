{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a19539",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6915d",
   "metadata": {},
   "source": [
    "Download dataset from this link:\n",
    "\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b394a",
   "metadata": {},
   "source": [
    "# Description about dataset::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6933f0",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "\n",
    "\n",
    "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b347756",
   "metadata": {},
   "source": [
    "# WORKFLOW :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a04f39",
   "metadata": {},
   "source": [
    "1.Load Data\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "\n",
    "3.Standardized the Input Variables. \n",
    "\n",
    "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "\n",
    "7.Train the Model with Epochs (100).\n",
    "\n",
    "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "9.Prediction should be > 92%\n",
    "10.Evaluation Step\n",
    "11Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67d5e2",
   "metadata": {},
   "source": [
    "# Task::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84798830",
   "metadata": {},
   "source": [
    "## Identify fraudulent credit card transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6341c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd91c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ec9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f694f47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084   \n",
       "3       1.247203  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "0      -0.991390 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993   \n",
       "1       0.489095 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783   \n",
       "2       0.717293 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857   \n",
       "3       0.507757 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622   \n",
       "4       1.345852 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "0       0.251412 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1      -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2       0.524980  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3      -0.208038 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4       0.408542 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "0       0.133558 -0.021053  149.62      0  \n",
       "1      -0.008983  0.014724    2.69      0  \n",
       "2      -0.055353 -0.059752  378.66      0  \n",
       "3       0.062723  0.061458  123.50      0  \n",
       "4       0.219422  0.215153   69.99      0  \n",
       "...          ...       ...     ...    ...  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a78f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud=df[df[\"Class\"]==0]\n",
    "fraud = df[df[\"Class\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4e53c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6433b380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da7062",
   "metadata": {},
   "source": [
    "Balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d2b5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud = non_fraud.sample(fraud.shape[0])\n",
    "data = fraud.append(non_fraud, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2e04d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>3.202033</td>\n",
       "      <td>-2.899907</td>\n",
       "      <td>-0.595222</td>\n",
       "      <td>-4.289254</td>\n",
       "      <td>0.389724</td>\n",
       "      <td>-1.140747</td>\n",
       "      <td>-2.830056</td>\n",
       "      <td>-0.016822</td>\n",
       "      <td>0.416956</td>\n",
       "      <td>0.126911</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>-0.838587</td>\n",
       "      <td>-0.414575</td>\n",
       "      <td>-0.503141</td>\n",
       "      <td>0.676502</td>\n",
       "      <td>-1.692029</td>\n",
       "      <td>2.000635</td>\n",
       "      <td>0.666780</td>\n",
       "      <td>0.599717</td>\n",
       "      <td>1.725321</td>\n",
       "      <td>0.283345</td>\n",
       "      <td>2.102339</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>-1.525412</td>\n",
       "      <td>2.032912</td>\n",
       "      <td>-6.560124</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>-1.470102</td>\n",
       "      <td>-0.698826</td>\n",
       "      <td>-2.282194</td>\n",
       "      <td>-4.781831</td>\n",
       "      <td>-2.615665</td>\n",
       "      <td>-1.334441</td>\n",
       "      <td>-0.430022</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>4.895844</td>\n",
       "      <td>-10.912819</td>\n",
       "      <td>0.184372</td>\n",
       "      <td>-6.771097</td>\n",
       "      <td>-0.007326</td>\n",
       "      <td>-7.358083</td>\n",
       "      <td>-12.598419</td>\n",
       "      <td>-5.131549</td>\n",
       "      <td>0.308334</td>\n",
       "      <td>-0.171608</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>-2.447469</td>\n",
       "      <td>2.101344</td>\n",
       "      <td>-4.609628</td>\n",
       "      <td>1.464378</td>\n",
       "      <td>-6.079337</td>\n",
       "      <td>-0.339237</td>\n",
       "      <td>2.581851</td>\n",
       "      <td>6.739384</td>\n",
       "      <td>3.042493</td>\n",
       "      <td>-2.721853</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>148629.0</td>\n",
       "      <td>0.340412</td>\n",
       "      <td>0.132211</td>\n",
       "      <td>-2.229970</td>\n",
       "      <td>-1.599404</td>\n",
       "      <td>3.150232</td>\n",
       "      <td>3.295249</td>\n",
       "      <td>0.775382</td>\n",
       "      <td>0.609661</td>\n",
       "      <td>0.540504</td>\n",
       "      <td>-1.156649</td>\n",
       "      <td>-0.028236</td>\n",
       "      <td>-0.103127</td>\n",
       "      <td>-0.520212</td>\n",
       "      <td>-1.469495</td>\n",
       "      <td>-0.418274</td>\n",
       "      <td>-0.160375</td>\n",
       "      <td>0.649919</td>\n",
       "      <td>0.084306</td>\n",
       "      <td>-0.349920</td>\n",
       "      <td>0.099114</td>\n",
       "      <td>-0.002266</td>\n",
       "      <td>0.163861</td>\n",
       "      <td>0.493488</td>\n",
       "      <td>0.568806</td>\n",
       "      <td>-1.919060</td>\n",
       "      <td>-0.465749</td>\n",
       "      <td>0.200354</td>\n",
       "      <td>0.167314</td>\n",
       "      <td>91.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>59221.0</td>\n",
       "      <td>-1.761013</td>\n",
       "      <td>-2.986331</td>\n",
       "      <td>1.980669</td>\n",
       "      <td>-1.359352</td>\n",
       "      <td>1.642570</td>\n",
       "      <td>0.308636</td>\n",
       "      <td>-2.195809</td>\n",
       "      <td>0.648208</td>\n",
       "      <td>-2.310869</td>\n",
       "      <td>1.518244</td>\n",
       "      <td>2.070943</td>\n",
       "      <td>-0.392154</td>\n",
       "      <td>-0.212365</td>\n",
       "      <td>-0.093968</td>\n",
       "      <td>1.464634</td>\n",
       "      <td>-1.736504</td>\n",
       "      <td>1.609771</td>\n",
       "      <td>-1.144589</td>\n",
       "      <td>-0.645036</td>\n",
       "      <td>0.363488</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.041679</td>\n",
       "      <td>0.626085</td>\n",
       "      <td>-1.088218</td>\n",
       "      <td>-0.839165</td>\n",
       "      <td>-0.285131</td>\n",
       "      <td>-0.018851</td>\n",
       "      <td>-0.060223</td>\n",
       "      <td>35.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>83063.0</td>\n",
       "      <td>1.302378</td>\n",
       "      <td>-0.606529</td>\n",
       "      <td>-0.681986</td>\n",
       "      <td>-1.904603</td>\n",
       "      <td>1.326623</td>\n",
       "      <td>3.436312</td>\n",
       "      <td>-1.145127</td>\n",
       "      <td>0.959147</td>\n",
       "      <td>1.671302</td>\n",
       "      <td>-1.022946</td>\n",
       "      <td>-0.191423</td>\n",
       "      <td>0.631027</td>\n",
       "      <td>0.031907</td>\n",
       "      <td>-0.031425</td>\n",
       "      <td>1.446627</td>\n",
       "      <td>-0.121820</td>\n",
       "      <td>-0.651405</td>\n",
       "      <td>0.617970</td>\n",
       "      <td>0.927600</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>-0.064208</td>\n",
       "      <td>-0.080587</td>\n",
       "      <td>-0.072991</td>\n",
       "      <td>1.018136</td>\n",
       "      <td>0.663575</td>\n",
       "      <td>-0.671323</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.028697</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>160177.0</td>\n",
       "      <td>0.631670</td>\n",
       "      <td>-4.507367</td>\n",
       "      <td>-2.518337</td>\n",
       "      <td>-1.687783</td>\n",
       "      <td>-0.132850</td>\n",
       "      <td>4.369624</td>\n",
       "      <td>-1.063966</td>\n",
       "      <td>0.853060</td>\n",
       "      <td>-0.717894</td>\n",
       "      <td>0.970412</td>\n",
       "      <td>-0.619762</td>\n",
       "      <td>-0.315555</td>\n",
       "      <td>0.334333</td>\n",
       "      <td>-0.664237</td>\n",
       "      <td>-0.901369</td>\n",
       "      <td>-0.838678</td>\n",
       "      <td>0.833393</td>\n",
       "      <td>-0.510502</td>\n",
       "      <td>-0.050295</td>\n",
       "      <td>1.287540</td>\n",
       "      <td>-0.056155</td>\n",
       "      <td>-1.449865</td>\n",
       "      <td>-0.232752</td>\n",
       "      <td>0.690979</td>\n",
       "      <td>-0.780149</td>\n",
       "      <td>-0.540451</td>\n",
       "      <td>-0.081099</td>\n",
       "      <td>0.099420</td>\n",
       "      <td>835.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>166248.0</td>\n",
       "      <td>-0.058441</td>\n",
       "      <td>0.592053</td>\n",
       "      <td>0.119334</td>\n",
       "      <td>-0.380352</td>\n",
       "      <td>1.069272</td>\n",
       "      <td>-1.161934</td>\n",
       "      <td>1.335538</td>\n",
       "      <td>-0.922225</td>\n",
       "      <td>0.304326</td>\n",
       "      <td>0.279083</td>\n",
       "      <td>-0.663319</td>\n",
       "      <td>0.182504</td>\n",
       "      <td>0.843751</td>\n",
       "      <td>-0.289423</td>\n",
       "      <td>0.544021</td>\n",
       "      <td>-0.577715</td>\n",
       "      <td>-0.793048</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.118760</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>0.286361</td>\n",
       "      <td>1.259836</td>\n",
       "      <td>-0.200743</td>\n",
       "      <td>-0.048938</td>\n",
       "      <td>-0.386880</td>\n",
       "      <td>-0.251251</td>\n",
       "      <td>-0.616839</td>\n",
       "      <td>-0.267098</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "1       472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "2      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "3      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "4      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "979  148629.0  0.340412  0.132211 -2.229970 -1.599404  3.150232  3.295249   \n",
       "980   59221.0 -1.761013 -2.986331  1.980669 -1.359352  1.642570  0.308636   \n",
       "981   83063.0  1.302378 -0.606529 -0.681986 -1.904603  1.326623  3.436312   \n",
       "982  160177.0  0.631670 -4.507367 -2.518337 -1.687783 -0.132850  4.369624   \n",
       "983  166248.0 -0.058441  0.592053  0.119334 -0.380352  1.069272 -1.161934   \n",
       "\n",
       "           V7        V8        V9       V10       V11        V12       V13  \\\n",
       "0   -2.537387  1.391657 -2.770089 -2.772272  3.202033  -2.899907 -0.595222   \n",
       "1    0.325574 -0.067794 -0.270953 -0.838587 -0.414575  -0.503141  0.676502   \n",
       "2    0.562320 -0.399147 -0.238253 -1.525412  2.032912  -6.560124  0.022937   \n",
       "3   -3.496197 -0.248778 -0.247768 -4.801637  4.895844 -10.912819  0.184372   \n",
       "4    1.713445 -0.496358 -1.282858 -2.447469  2.101344  -4.609628  1.464378   \n",
       "..        ...       ...       ...       ...       ...        ...       ...   \n",
       "979  0.775382  0.609661  0.540504 -1.156649 -0.028236  -0.103127 -0.520212   \n",
       "980 -2.195809  0.648208 -2.310869  1.518244  2.070943  -0.392154 -0.212365   \n",
       "981 -1.145127  0.959147  1.671302 -1.022946 -0.191423   0.631027  0.031907   \n",
       "982 -1.063966  0.853060 -0.717894  0.970412 -0.619762  -0.315555  0.334333   \n",
       "983  1.335538 -0.922225  0.304326  0.279083 -0.663319   0.182504  0.843751   \n",
       "\n",
       "          V14       V15       V16        V17       V18       V19       V20  \\\n",
       "0   -4.289254  0.389724 -1.140747  -2.830056 -0.016822  0.416956  0.126911   \n",
       "1   -1.692029  2.000635  0.666780   0.599717  1.725321  0.283345  2.102339   \n",
       "2   -1.470102 -0.698826 -2.282194  -4.781831 -2.615665 -1.334441 -0.430022   \n",
       "3   -6.771097 -0.007326 -7.358083 -12.598419 -5.131549  0.308334 -0.171608   \n",
       "4   -6.079337 -0.339237  2.581851   6.739384  3.042493 -2.721853  0.009061   \n",
       "..        ...       ...       ...        ...       ...       ...       ...   \n",
       "979 -1.469495 -0.418274 -0.160375   0.649919  0.084306 -0.349920  0.099114   \n",
       "980 -0.093968  1.464634 -1.736504   1.609771 -1.144589 -0.645036  0.363488   \n",
       "981 -0.031425  1.446627 -0.121820  -0.651405  0.617970  0.927600  0.005757   \n",
       "982 -0.664237 -0.901369 -0.838678   0.833393 -0.510502 -0.050295  1.287540   \n",
       "983 -0.289423  0.544021 -0.577715  -0.793048  0.002430  0.118760 -0.051453   \n",
       "\n",
       "          V21       V22       V23       V24       V25       V26       V27  \\\n",
       "0    0.517232 -0.035049 -0.465211  0.320198  0.044519  0.177840  0.261145   \n",
       "1    0.661696  0.435477  1.375966 -0.293803  0.279798 -0.145362 -0.252773   \n",
       "2   -0.294166 -0.932391  0.172726 -0.087330 -0.156114 -0.542628  0.039566   \n",
       "3    0.573574  0.176968 -0.436207 -0.053502  0.252405 -0.657488 -0.827136   \n",
       "4   -0.379068 -0.704181 -0.656805 -1.632653  1.488901  0.566797 -0.010016   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "979 -0.002266  0.163861  0.493488  0.568806 -1.919060 -0.465749  0.200354   \n",
       "980  0.044059  0.041679  0.626085 -1.088218 -0.839165 -0.285131 -0.018851   \n",
       "981 -0.064208 -0.080587 -0.072991  1.018136  0.663575 -0.671323  0.096801   \n",
       "982 -0.056155 -1.449865 -0.232752  0.690979 -0.780149 -0.540451 -0.081099   \n",
       "983  0.286361  1.259836 -0.200743 -0.048938 -0.386880 -0.251251 -0.616839   \n",
       "\n",
       "          V28  Amount  Class  \n",
       "0   -0.143276    0.00      1  \n",
       "1    0.035764  529.00      1  \n",
       "2   -0.153029  239.93      1  \n",
       "3    0.849573   59.00      1  \n",
       "4    0.146793    1.00      1  \n",
       "..        ...     ...    ...  \n",
       "979  0.167314   91.91      0  \n",
       "980 -0.060223   35.40      0  \n",
       "981  0.028697    1.00      0  \n",
       "982  0.099420  835.00      0  \n",
       "983 -0.267098    0.89      0  \n",
       "\n",
       "[984 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a6cd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3db0f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      False\n",
       "V1        False\n",
       "V2        False\n",
       "V3        False\n",
       "V4        False\n",
       "V5        False\n",
       "V6        False\n",
       "V7        False\n",
       "V8        False\n",
       "V9        False\n",
       "V10       False\n",
       "V11       False\n",
       "V12       False\n",
       "V13       False\n",
       "V14       False\n",
       "V15       False\n",
       "V16       False\n",
       "V17       False\n",
       "V18       False\n",
       "V19       False\n",
       "V20       False\n",
       "V21       False\n",
       "V22       False\n",
       "V23       False\n",
       "V24       False\n",
       "V25       False\n",
       "V26       False\n",
       "V27       False\n",
       "V28       False\n",
       "Amount    False\n",
       "Class     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c491608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "931520f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 984 entries, 0 to 983\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    984 non-null    float64\n",
      " 1   V1      984 non-null    float64\n",
      " 2   V2      984 non-null    float64\n",
      " 3   V3      984 non-null    float64\n",
      " 4   V4      984 non-null    float64\n",
      " 5   V5      984 non-null    float64\n",
      " 6   V6      984 non-null    float64\n",
      " 7   V7      984 non-null    float64\n",
      " 8   V8      984 non-null    float64\n",
      " 9   V9      984 non-null    float64\n",
      " 10  V10     984 non-null    float64\n",
      " 11  V11     984 non-null    float64\n",
      " 12  V12     984 non-null    float64\n",
      " 13  V13     984 non-null    float64\n",
      " 14  V14     984 non-null    float64\n",
      " 15  V15     984 non-null    float64\n",
      " 16  V16     984 non-null    float64\n",
      " 17  V17     984 non-null    float64\n",
      " 18  V18     984 non-null    float64\n",
      " 19  V19     984 non-null    float64\n",
      " 20  V20     984 non-null    float64\n",
      " 21  V21     984 non-null    float64\n",
      " 22  V22     984 non-null    float64\n",
      " 23  V23     984 non-null    float64\n",
      " 24  V24     984 non-null    float64\n",
      " 25  V25     984 non-null    float64\n",
      " 26  V26     984 non-null    float64\n",
      " 27  V27     984 non-null    float64\n",
      " 28  V28     984 non-null    float64\n",
      " 29  Amount  984 non-null    float64\n",
      " 30  Class   984 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 238.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "355af169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>984.0</td>\n",
       "      <td>88416.980691</td>\n",
       "      <td>47626.738666</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>48524.750000</td>\n",
       "      <td>82291.000000</td>\n",
       "      <td>133430.250000</td>\n",
       "      <td>172502.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-2.360191</td>\n",
       "      <td>5.511939</td>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-2.858263</td>\n",
       "      <td>-0.768559</td>\n",
       "      <td>1.068827</td>\n",
       "      <td>2.289557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>984.0</td>\n",
       "      <td>1.785147</td>\n",
       "      <td>3.729886</td>\n",
       "      <td>-15.650427</td>\n",
       "      <td>-0.176052</td>\n",
       "      <td>0.964356</td>\n",
       "      <td>2.814266</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-3.515816</td>\n",
       "      <td>6.216683</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-5.113334</td>\n",
       "      <td>-1.376748</td>\n",
       "      <td>0.329488</td>\n",
       "      <td>3.178416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>984.0</td>\n",
       "      <td>2.255601</td>\n",
       "      <td>3.205419</td>\n",
       "      <td>-3.599023</td>\n",
       "      <td>-0.108051</td>\n",
       "      <td>1.307692</td>\n",
       "      <td>4.274853</td>\n",
       "      <td>12.114672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-1.570120</td>\n",
       "      <td>4.250013</td>\n",
       "      <td>-22.105532</td>\n",
       "      <td>-1.873814</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.449908</td>\n",
       "      <td>11.095089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-0.655405</td>\n",
       "      <td>1.827281</td>\n",
       "      <td>-7.300573</td>\n",
       "      <td>-1.564562</td>\n",
       "      <td>-0.654786</td>\n",
       "      <td>0.090037</td>\n",
       "      <td>9.291293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-2.804745</td>\n",
       "      <td>5.878016</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-3.105154</td>\n",
       "      <td>-0.670645</td>\n",
       "      <td>0.226119</td>\n",
       "      <td>19.194427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.274666</td>\n",
       "      <td>4.906128</td>\n",
       "      <td>-41.044261</td>\n",
       "      <td>-0.212663</td>\n",
       "      <td>0.177930</td>\n",
       "      <td>0.892259</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-1.320292</td>\n",
       "      <td>2.301905</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-2.338449</td>\n",
       "      <td>-0.751057</td>\n",
       "      <td>0.172148</td>\n",
       "      <td>4.109824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-2.823552</td>\n",
       "      <td>4.535716</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-4.593030</td>\n",
       "      <td>-0.810934</td>\n",
       "      <td>0.040699</td>\n",
       "      <td>6.071369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>984.0</td>\n",
       "      <td>1.885937</td>\n",
       "      <td>2.781858</td>\n",
       "      <td>-2.669574</td>\n",
       "      <td>-0.191726</td>\n",
       "      <td>1.086663</td>\n",
       "      <td>3.586130</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-3.130060</td>\n",
       "      <td>4.585078</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-5.495221</td>\n",
       "      <td>-0.826243</td>\n",
       "      <td>0.179698</td>\n",
       "      <td>2.053038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-0.062680</td>\n",
       "      <td>1.039577</td>\n",
       "      <td>-3.341613</td>\n",
       "      <td>-0.799323</td>\n",
       "      <td>-0.067956</td>\n",
       "      <td>0.660095</td>\n",
       "      <td>3.046663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-3.455378</td>\n",
       "      <td>4.675418</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-6.721799</td>\n",
       "      <td>-0.983169</td>\n",
       "      <td>0.163515</td>\n",
       "      <td>3.442422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.997098</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.563338</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.714494</td>\n",
       "      <td>2.471358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-2.072250</td>\n",
       "      <td>3.476350</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-3.543426</td>\n",
       "      <td>-0.603321</td>\n",
       "      <td>0.287189</td>\n",
       "      <td>3.139656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-3.330844</td>\n",
       "      <td>5.968001</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-5.302111</td>\n",
       "      <td>-0.507614</td>\n",
       "      <td>0.266517</td>\n",
       "      <td>6.739384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-1.114965</td>\n",
       "      <td>2.408196</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-1.777761</td>\n",
       "      <td>-0.309944</td>\n",
       "      <td>0.319826</td>\n",
       "      <td>3.790316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.361323</td>\n",
       "      <td>1.267509</td>\n",
       "      <td>-3.681904</td>\n",
       "      <td>-0.401851</td>\n",
       "      <td>0.226071</td>\n",
       "      <td>1.040829</td>\n",
       "      <td>5.228342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.215106</td>\n",
       "      <td>1.127692</td>\n",
       "      <td>-4.128186</td>\n",
       "      <td>-0.189972</td>\n",
       "      <td>0.028249</td>\n",
       "      <td>0.478305</td>\n",
       "      <td>12.720356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.371524</td>\n",
       "      <td>2.824416</td>\n",
       "      <td>-22.797604</td>\n",
       "      <td>-0.160842</td>\n",
       "      <td>0.136663</td>\n",
       "      <td>0.664181</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-0.021324</td>\n",
       "      <td>1.182467</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-0.547223</td>\n",
       "      <td>-0.012960</td>\n",
       "      <td>0.539074</td>\n",
       "      <td>8.361985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-0.017039</td>\n",
       "      <td>1.238028</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-0.239655</td>\n",
       "      <td>-0.031389</td>\n",
       "      <td>0.193798</td>\n",
       "      <td>13.321114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>984.0</td>\n",
       "      <td>-0.023797</td>\n",
       "      <td>0.552181</td>\n",
       "      <td>-2.028024</td>\n",
       "      <td>-0.382750</td>\n",
       "      <td>0.023862</td>\n",
       "      <td>0.392654</td>\n",
       "      <td>1.206213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>0.664394</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-0.301392</td>\n",
       "      <td>0.051690</td>\n",
       "      <td>0.388299</td>\n",
       "      <td>2.574408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.034699</td>\n",
       "      <td>0.487426</td>\n",
       "      <td>-1.330885</td>\n",
       "      <td>-0.290101</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>0.360384</td>\n",
       "      <td>2.745261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.083496</td>\n",
       "      <td>1.001838</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>0.043071</td>\n",
       "      <td>0.452338</td>\n",
       "      <td>3.052358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.040689</td>\n",
       "      <td>0.414887</td>\n",
       "      <td>-1.869290</td>\n",
       "      <td>-0.061229</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>0.208794</td>\n",
       "      <td>1.779364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>984.0</td>\n",
       "      <td>110.839787</td>\n",
       "      <td>294.275235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.022500</td>\n",
       "      <td>18.970000</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>5714.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>984.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count          mean           std         min           25%  \\\n",
       "Time    984.0  88416.980691  47626.738666  242.000000  48524.750000   \n",
       "V1      984.0     -2.360191      5.511939  -30.552380     -2.858263   \n",
       "V2      984.0      1.785147      3.729886  -15.650427     -0.176052   \n",
       "V3      984.0     -3.515816      6.216683  -31.103685     -5.113334   \n",
       "V4      984.0      2.255601      3.205419   -3.599023     -0.108051   \n",
       "V5      984.0     -1.570120      4.250013  -22.105532     -1.873814   \n",
       "V6      984.0     -0.655405      1.827281   -7.300573     -1.564562   \n",
       "V7      984.0     -2.804745      5.878016  -43.557242     -3.105154   \n",
       "V8      984.0      0.274666      4.906128  -41.044261     -0.212663   \n",
       "V9      984.0     -1.320292      2.301905  -13.434066     -2.338449   \n",
       "V10     984.0     -2.823552      4.535716  -24.588262     -4.593030   \n",
       "V11     984.0      1.885937      2.781858   -2.669574     -0.191726   \n",
       "V12     984.0     -3.130060      4.585078  -18.683715     -5.495221   \n",
       "V13     984.0     -0.062680      1.039577   -3.341613     -0.799323   \n",
       "V14     984.0     -3.455378      4.675418  -19.214325     -6.721799   \n",
       "V15     984.0      0.002401      0.997098   -4.498945     -0.563338   \n",
       "V16     984.0     -2.072250      3.476350  -14.129855     -3.543426   \n",
       "V17     984.0     -3.330844      5.968001  -25.162799     -5.302111   \n",
       "V18     984.0     -1.114965      2.408196   -9.498746     -1.777761   \n",
       "V19     984.0      0.361323      1.267509   -3.681904     -0.401851   \n",
       "V20     984.0      0.215106      1.127692   -4.128186     -0.189972   \n",
       "V21     984.0      0.371524      2.824416  -22.797604     -0.160842   \n",
       "V22     984.0     -0.021324      1.182467   -8.887017     -0.547223   \n",
       "V23     984.0     -0.017039      1.238028  -19.254328     -0.239655   \n",
       "V24     984.0     -0.023797      0.552181   -2.028024     -0.382750   \n",
       "V25     984.0      0.029989      0.664394   -4.781606     -0.301392   \n",
       "V26     984.0      0.034699      0.487426   -1.330885     -0.290101   \n",
       "V27     984.0      0.083496      1.001838   -7.263482     -0.062215   \n",
       "V28     984.0      0.040689      0.414887   -1.869290     -0.061229   \n",
       "Amount  984.0    110.839787    294.275235    0.000000      1.022500   \n",
       "Class   984.0      0.500000      0.500254    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    82291.000000  133430.250000  172502.000000  \n",
       "V1         -0.768559       1.068827       2.289557  \n",
       "V2          0.964356       2.814266      22.057729  \n",
       "V3         -1.376748       0.329488       3.178416  \n",
       "V4          1.307692       4.274853      12.114672  \n",
       "V5         -0.412995       0.449908      11.095089  \n",
       "V6         -0.654786       0.090037       9.291293  \n",
       "V7         -0.670645       0.226119      19.194427  \n",
       "V8          0.177930       0.892259      20.007208  \n",
       "V9         -0.751057       0.172148       4.109824  \n",
       "V10        -0.810934       0.040699       6.071369  \n",
       "V11         1.086663       3.586130      12.018913  \n",
       "V12        -0.826243       0.179698       2.053038  \n",
       "V13        -0.067956       0.660095       3.046663  \n",
       "V14        -0.983169       0.163515       3.442422  \n",
       "V15         0.015052       0.714494       2.471358  \n",
       "V16        -0.603321       0.287189       3.139656  \n",
       "V17        -0.507614       0.266517       6.739384  \n",
       "V18        -0.309944       0.319826       3.790316  \n",
       "V19         0.226071       1.040829       5.228342  \n",
       "V20         0.028249       0.478305      12.720356  \n",
       "V21         0.136663       0.664181      27.202839  \n",
       "V22        -0.012960       0.539074       8.361985  \n",
       "V23        -0.031389       0.193798      13.321114  \n",
       "V24         0.023862       0.392654       1.206213  \n",
       "V25         0.051690       0.388299       2.574408  \n",
       "V26        -0.002273       0.360384       2.745261  \n",
       "V27         0.043071       0.452338       3.052358  \n",
       "V28         0.035679       0.208794       1.779364  \n",
       "Amount     18.970000      99.990000    5714.200000  \n",
       "Class       0.500000       1.000000       1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f808920",
   "metadata": {},
   "source": [
    "Separating labels and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76f4ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['Class']\n",
    "data.drop(columns='Class', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "148942f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958c6d0",
   "metadata": {},
   "source": [
    "Converting dataframes into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce7b0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels.astype('float32'))\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ae5a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0dd6f",
   "metadata": {},
   "source": [
    "Splitting training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72ff411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05188199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_l, test_l = train_test_split(data, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7753e75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((688, 30), (688,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "364aca7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((296, 30), (296,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, test_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212358cc",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ffe003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43afd482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10073198, -0.28454851,  1.06925752, ...,  1.75678796,\n",
       "         2.3404394 , -0.13944218],\n",
       "       [-0.26664092,  0.42059521, -0.1603364 , ..., -0.18384758,\n",
       "        -0.37890525, -0.3665546 ],\n",
       "       [-0.4199344 , -0.18001123,  0.33393507, ..., -0.13099045,\n",
       "         0.16730906, -0.33651969],\n",
       "       ...,\n",
       "       [-0.83225318,  0.20011093, -0.1682758 , ..., -0.23856272,\n",
       "        -0.15801585, -0.2910426 ],\n",
       "       [-0.05453372,  0.59481092, -0.45492442, ..., -0.07102202,\n",
       "        -0.01555256,  0.09322215],\n",
       "       [ 1.47416602,  0.8341162 , -0.5871118 , ..., -0.18781608,\n",
       "        -0.35055586, -0.30891185]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25a795",
   "metadata": {},
   "source": [
    "Splitting partial train data and Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d307ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_train, val_train, partial_l, val_l = train_test_split(train_data, train_l, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3338b5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138, 30), (138,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_train.shape, val_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff1b68",
   "metadata": {},
   "source": [
    "<h3>Building Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4dc79b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e363664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(act):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation= act,input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(8, activation= act))\n",
    "    model.add(layers.Dense(6, activation= act))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics='acc')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdfe35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = build_model('relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adb1c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "550/550 [==============================] - 2s 3ms/step - loss: 0.5031 - acc: 0.8236 - val_loss: 0.3287 - val_acc: 0.8768\n",
      "Epoch 2/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.2549 - acc: 0.9109 - val_loss: 0.2943 - val_acc: 0.8841\n",
      "Epoch 3/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.2215 - acc: 0.9164 - val_loss: 0.2648 - val_acc: 0.8986\n",
      "Epoch 4/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.2096 - acc: 0.9218 - val_loss: 0.2359 - val_acc: 0.9130\n",
      "Epoch 5/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1923 - acc: 0.9236 - val_loss: 0.2099 - val_acc: 0.9348\n",
      "Epoch 6/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1824 - acc: 0.9364 - val_loss: 0.2117 - val_acc: 0.9348\n",
      "Epoch 7/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1835 - acc: 0.9400 - val_loss: 0.2085 - val_acc: 0.9348\n",
      "Epoch 8/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1745 - acc: 0.9400 - val_loss: 0.1956 - val_acc: 0.9348\n",
      "Epoch 9/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1671 - acc: 0.9382 - val_loss: 0.1939 - val_acc: 0.9348\n",
      "Epoch 10/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1672 - acc: 0.9436 - val_loss: 0.2035 - val_acc: 0.9275\n",
      "Epoch 11/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1591 - acc: 0.9491 - val_loss: 0.2210 - val_acc: 0.9275\n",
      "Epoch 12/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1667 - acc: 0.9455 - val_loss: 0.2094 - val_acc: 0.9275\n",
      "Epoch 13/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1540 - acc: 0.9491 - val_loss: 0.2331 - val_acc: 0.9275\n",
      "Epoch 14/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1607 - acc: 0.9473 - val_loss: 0.2230 - val_acc: 0.9275\n",
      "Epoch 15/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1489 - acc: 0.9509 - val_loss: 0.2403 - val_acc: 0.9203\n",
      "Epoch 16/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1501 - acc: 0.9527 - val_loss: 0.2432 - val_acc: 0.9203\n",
      "Epoch 17/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1494 - acc: 0.9509 - val_loss: 0.2407 - val_acc: 0.9275\n",
      "Epoch 18/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1475 - acc: 0.9545 - val_loss: 0.2424 - val_acc: 0.9275\n",
      "Epoch 19/100\n",
      "550/550 [==============================] - 2s 3ms/step - loss: 0.1487 - acc: 0.9582 - val_loss: 0.2430 - val_acc: 0.9348\n",
      "Epoch 20/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1394 - acc: 0.9545 - val_loss: 0.2604 - val_acc: 0.9275\n",
      "Epoch 21/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1404 - acc: 0.9545 - val_loss: 0.2514 - val_acc: 0.9348\n",
      "Epoch 22/100\n",
      "550/550 [==============================] - ETA: 0s - loss: 0.1474 - acc: 0.954 - 1s 2ms/step - loss: 0.1469 - acc: 0.9545 - val_loss: 0.2545 - val_acc: 0.9275\n",
      "Epoch 23/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1360 - acc: 0.9618 - val_loss: 0.2530 - val_acc: 0.9275\n",
      "Epoch 24/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1393 - acc: 0.9564 - val_loss: 0.2593 - val_acc: 0.9275\n",
      "Epoch 25/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1361 - acc: 0.9527 - val_loss: 0.2639 - val_acc: 0.9203\n",
      "Epoch 26/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1309 - acc: 0.9564 - val_loss: 0.2699 - val_acc: 0.9203\n",
      "Epoch 27/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1301 - acc: 0.9618 - val_loss: 0.2866 - val_acc: 0.9275\n",
      "Epoch 28/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1245 - acc: 0.9618 - val_loss: 0.3236 - val_acc: 0.9348\n",
      "Epoch 29/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1296 - acc: 0.9655 - val_loss: 0.2931 - val_acc: 0.9275\n",
      "Epoch 30/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1156 - acc: 0.9655 - val_loss: 0.3408 - val_acc: 0.9348\n",
      "Epoch 31/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1296 - acc: 0.9636 - val_loss: 0.3597 - val_acc: 0.9275\n",
      "Epoch 32/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1333 - acc: 0.9636 - val_loss: 0.3472 - val_acc: 0.9348\n",
      "Epoch 33/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1243 - acc: 0.9636 - val_loss: 0.3457 - val_acc: 0.9275\n",
      "Epoch 34/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1303 - acc: 0.9636 - val_loss: 0.3425 - val_acc: 0.9203\n",
      "Epoch 35/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1263 - acc: 0.9673 - val_loss: 0.3542 - val_acc: 0.9203\n",
      "Epoch 36/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1252 - acc: 0.9636 - val_loss: 0.3558 - val_acc: 0.9275\n",
      "Epoch 37/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1139 - acc: 0.9636 - val_loss: 0.3634 - val_acc: 0.9203\n",
      "Epoch 38/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1137 - acc: 0.9655 - val_loss: 0.3756 - val_acc: 0.9275\n",
      "Epoch 39/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1095 - acc: 0.9673 - val_loss: 0.4322 - val_acc: 0.9348\n",
      "Epoch 40/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1353 - acc: 0.9655 - val_loss: 0.3990 - val_acc: 0.9275\n",
      "Epoch 41/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1323 - acc: 0.9709 - val_loss: 0.3831 - val_acc: 0.9275\n",
      "Epoch 42/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1155 - acc: 0.9691 - val_loss: 0.3782 - val_acc: 0.9275\n",
      "Epoch 43/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1135 - acc: 0.9691 - val_loss: 0.3951 - val_acc: 0.9275\n",
      "Epoch 44/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1175 - acc: 0.9727 - val_loss: 0.4173 - val_acc: 0.9275\n",
      "Epoch 45/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1213 - acc: 0.9709 - val_loss: 0.4297 - val_acc: 0.9275\n",
      "Epoch 46/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1065 - acc: 0.9709 - val_loss: 0.4385 - val_acc: 0.9275\n",
      "Epoch 47/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1176 - acc: 0.9709 - val_loss: 0.4512 - val_acc: 0.9275\n",
      "Epoch 48/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1210 - acc: 0.9709 - val_loss: 0.4379 - val_acc: 0.9275\n",
      "Epoch 49/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1093 - acc: 0.9727 - val_loss: 0.4577 - val_acc: 0.9275\n",
      "Epoch 50/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1090 - acc: 0.9727 - val_loss: 0.4634 - val_acc: 0.9275\n",
      "Epoch 51/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1129 - acc: 0.9709 - val_loss: 0.4505 - val_acc: 0.9275\n",
      "Epoch 52/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1039 - acc: 0.9745 - val_loss: 0.4808 - val_acc: 0.9275\n",
      "Epoch 53/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1116 - acc: 0.9764 - val_loss: 0.5068 - val_acc: 0.9275\n",
      "Epoch 54/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1238 - acc: 0.9745 - val_loss: 0.5448 - val_acc: 0.9275\n",
      "Epoch 55/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1168 - acc: 0.9764 - val_loss: 0.5377 - val_acc: 0.9275\n",
      "Epoch 56/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1386 - acc: 0.9745 - val_loss: 0.5368 - val_acc: 0.9203\n",
      "Epoch 57/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1146 - acc: 0.9709 - val_loss: 0.5352 - val_acc: 0.9203\n",
      "Epoch 58/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1007 - acc: 0.9745 - val_loss: 0.5635 - val_acc: 0.9275\n",
      "Epoch 59/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1138 - acc: 0.9745 - val_loss: 0.5590 - val_acc: 0.9275\n",
      "Epoch 60/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1091 - acc: 0.9764 - val_loss: 0.5490 - val_acc: 0.9203\n",
      "Epoch 61/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1026 - acc: 0.9764 - val_loss: 0.5917 - val_acc: 0.9203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1166 - acc: 0.9727 - val_loss: 0.5946 - val_acc: 0.9203\n",
      "Epoch 63/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1099 - acc: 0.9782 - val_loss: 0.6000 - val_acc: 0.9203\n",
      "Epoch 64/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1126 - acc: 0.9782 - val_loss: 0.6224 - val_acc: 0.9203\n",
      "Epoch 65/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1178 - acc: 0.9745 - val_loss: 0.6117 - val_acc: 0.9203\n",
      "Epoch 66/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1036 - acc: 0.9782 - val_loss: 0.6086 - val_acc: 0.9203\n",
      "Epoch 67/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1053 - acc: 0.9800 - val_loss: 0.6216 - val_acc: 0.9203\n",
      "Epoch 68/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.0986 - acc: 0.9818 - val_loss: 0.6391 - val_acc: 0.9275\n",
      "Epoch 69/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1106 - acc: 0.9745 - val_loss: 0.6500 - val_acc: 0.9203\n",
      "Epoch 70/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1199 - acc: 0.9764 - val_loss: 0.6600 - val_acc: 0.9203\n",
      "Epoch 71/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1033 - acc: 0.9782 - val_loss: 0.6933 - val_acc: 0.9275\n",
      "Epoch 72/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1025 - acc: 0.9782 - val_loss: 0.6789 - val_acc: 0.9203\n",
      "Epoch 73/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1072 - acc: 0.9800 - val_loss: 0.6937 - val_acc: 0.9203\n",
      "Epoch 74/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1124 - acc: 0.9782 - val_loss: 0.7087 - val_acc: 0.9203\n",
      "Epoch 75/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1030 - acc: 0.9782 - val_loss: 0.7384 - val_acc: 0.9203\n",
      "Epoch 76/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1085 - acc: 0.9800 - val_loss: 0.7619 - val_acc: 0.9130\n",
      "Epoch 77/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1076 - acc: 0.9782 - val_loss: 0.7698 - val_acc: 0.9130\n",
      "Epoch 78/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1111 - acc: 0.9782 - val_loss: 0.7974 - val_acc: 0.9203\n",
      "Epoch 79/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1003 - acc: 0.9800 - val_loss: 0.8153 - val_acc: 0.9130\n",
      "Epoch 80/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.0971 - acc: 0.9836 - val_loss: 0.8053 - val_acc: 0.9058\n",
      "Epoch 81/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1111 - acc: 0.9800 - val_loss: 0.8054 - val_acc: 0.9203\n",
      "Epoch 82/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1018 - acc: 0.9800 - val_loss: 0.8223 - val_acc: 0.9130\n",
      "Epoch 83/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1078 - acc: 0.9818 - val_loss: 0.8552 - val_acc: 0.9058\n",
      "Epoch 84/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0976 - acc: 0.9800 - val_loss: 0.8662 - val_acc: 0.9058\n",
      "Epoch 85/100\n",
      "550/550 [==============================] - 2s 4ms/step - loss: 0.0956 - acc: 0.9764 - val_loss: 0.9043 - val_acc: 0.8986\n",
      "Epoch 86/100\n",
      "550/550 [==============================] - 2s 3ms/step - loss: 0.1090 - acc: 0.9818 - val_loss: 0.9000 - val_acc: 0.9058\n",
      "Epoch 87/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1041 - acc: 0.9818 - val_loss: 0.9828 - val_acc: 0.9130\n",
      "Epoch 88/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1120 - acc: 0.9800 - val_loss: 0.9732 - val_acc: 0.9058\n",
      "Epoch 89/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1097 - acc: 0.9818 - val_loss: 0.9865 - val_acc: 0.9058\n",
      "Epoch 90/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1085 - acc: 0.9818 - val_loss: 0.9743 - val_acc: 0.9130\n",
      "Epoch 91/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1057 - acc: 0.9836 - val_loss: 1.0488 - val_acc: 0.9058\n",
      "Epoch 92/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1139 - acc: 0.9800 - val_loss: 1.0074 - val_acc: 0.8986\n",
      "Epoch 93/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1015 - acc: 0.9782 - val_loss: 1.0451 - val_acc: 0.8913\n",
      "Epoch 94/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.0999 - acc: 0.9836 - val_loss: 1.0706 - val_acc: 0.8913\n",
      "Epoch 95/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0979 - acc: 0.9855 - val_loss: 1.1442 - val_acc: 0.8986\n",
      "Epoch 96/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1255 - acc: 0.9782 - val_loss: 1.1985 - val_acc: 0.8913\n",
      "Epoch 97/100\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1081 - acc: 0.9800 - val_loss: 1.1845 - val_acc: 0.8986\n",
      "Epoch 98/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.0921 - acc: 0.9836 - val_loss: 1.2184 - val_acc: 0.8913\n",
      "Epoch 99/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1064 - acc: 0.9818 - val_loss: 1.1886 - val_acc: 0.8913\n",
      "Epoch 100/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1056 - acc: 0.9818 - val_loss: 1.2092 - val_acc: 0.8986\n"
     ]
    }
   ],
   "source": [
    "history = network.fit(partial_train, partial_l, epochs=100, batch_size=1, validation_data=(val_train, val_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2902d064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.historytory.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b5438",
   "metadata": {},
   "source": [
    "### Plot loss and val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9425d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, loss, 'ro', label='Train loss')\n",
    "plt.plot(epochs, val_loss, 'g-', label='Validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cae4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ab52d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(6, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4cc7d8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.5284 - acc: 0.8273 - val_loss: 0.4021 - val_acc: 0.8841\n",
      "Epoch 2/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.3166 - acc: 0.9055 - val_loss: 0.2830 - val_acc: 0.8913\n",
      "Epoch 3/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.2388 - acc: 0.9200 - val_loss: 0.2548 - val_acc: 0.9058\n",
      "Epoch 4/100\n",
      "550/550 [==============================] - 1s 3ms/step - loss: 0.2190 - acc: 0.9327 - val_loss: 0.2363 - val_acc: 0.9203\n",
      "Epoch 5/100\n",
      "550/550 [==============================] - 2s 3ms/step - loss: 0.2130 - acc: 0.9382 - val_loss: 0.2223 - val_acc: 0.9203\n",
      "Epoch 6/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1978 - acc: 0.9400 - val_loss: 0.2166 - val_acc: 0.9275\n",
      "Epoch 7/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1919 - acc: 0.9400 - val_loss: 0.2061 - val_acc: 0.9203\n",
      "Epoch 8/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1763 - acc: 0.9436 - val_loss: 0.2076 - val_acc: 0.9203\n",
      "Epoch 9/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1866 - acc: 0.9455 - val_loss: 0.2010 - val_acc: 0.9275\n",
      "Epoch 10/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1795 - acc: 0.9436 - val_loss: 0.2043 - val_acc: 0.9348\n",
      "Epoch 11/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1759 - acc: 0.9527 - val_loss: 0.2455 - val_acc: 0.9275\n",
      "Epoch 12/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1755 - acc: 0.9455 - val_loss: 0.2176 - val_acc: 0.9348\n",
      "Epoch 13/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1685 - acc: 0.9545 - val_loss: 0.2637 - val_acc: 0.9275\n",
      "Epoch 14/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1734 - acc: 0.9509 - val_loss: 0.2316 - val_acc: 0.9275\n",
      "Epoch 15/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1760 - acc: 0.9527 - val_loss: 0.2526 - val_acc: 0.9348\n",
      "Epoch 16/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1824 - acc: 0.9509 - val_loss: 0.2633 - val_acc: 0.9203\n",
      "Epoch 17/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1803 - acc: 0.9509 - val_loss: 0.2569 - val_acc: 0.9275\n",
      "Epoch 18/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1741 - acc: 0.9473 - val_loss: 0.2686 - val_acc: 0.9275\n",
      "Epoch 19/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1578 - acc: 0.9545 - val_loss: 0.2477 - val_acc: 0.9348\n",
      "Epoch 20/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1557 - acc: 0.9509 - val_loss: 0.2588 - val_acc: 0.9348\n",
      "Epoch 21/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1588 - acc: 0.9582 - val_loss: 0.2730 - val_acc: 0.9275\n",
      "Epoch 22/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1660 - acc: 0.9527 - val_loss: 0.2663 - val_acc: 0.9348\n",
      "Epoch 23/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1586 - acc: 0.9582 - val_loss: 0.2636 - val_acc: 0.9275\n",
      "Epoch 24/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1543 - acc: 0.9491 - val_loss: 0.2709 - val_acc: 0.9348\n",
      "Epoch 25/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1516 - acc: 0.9564 - val_loss: 0.3052 - val_acc: 0.9130\n",
      "Epoch 26/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1537 - acc: 0.9636 - val_loss: 0.2722 - val_acc: 0.9348\n",
      "Epoch 27/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1641 - acc: 0.9600 - val_loss: 0.2722 - val_acc: 0.9203\n",
      "Epoch 28/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1499 - acc: 0.9564 - val_loss: 0.2856 - val_acc: 0.9348\n",
      "Epoch 29/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1441 - acc: 0.9527 - val_loss: 0.2941 - val_acc: 0.9348\n",
      "Epoch 30/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1521 - acc: 0.9527 - val_loss: 0.2919 - val_acc: 0.9275\n",
      "Epoch 31/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1455 - acc: 0.9600 - val_loss: 0.2682 - val_acc: 0.9203\n",
      "Epoch 32/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1412 - acc: 0.9509 - val_loss: 0.2611 - val_acc: 0.9348\n",
      "Epoch 33/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1384 - acc: 0.9600 - val_loss: 0.2725 - val_acc: 0.9348\n",
      "Epoch 34/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1324 - acc: 0.9582 - val_loss: 0.2729 - val_acc: 0.9348\n",
      "Epoch 35/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1324 - acc: 0.9582 - val_loss: 0.2821 - val_acc: 0.9348\n",
      "Epoch 36/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1418 - acc: 0.9618 - val_loss: 0.2675 - val_acc: 0.9348\n",
      "Epoch 37/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1358 - acc: 0.9600 - val_loss: 0.2743 - val_acc: 0.9275\n",
      "Epoch 38/100\n",
      "550/550 [==============================] - 1s 3ms/step - loss: 0.1420 - acc: 0.9564 - val_loss: 0.2791 - val_acc: 0.9420\n",
      "Epoch 39/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1534 - acc: 0.9545 - val_loss: 0.2784 - val_acc: 0.9275\n",
      "Epoch 40/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1394 - acc: 0.9527 - val_loss: 0.2816 - val_acc: 0.9275\n",
      "Epoch 41/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1434 - acc: 0.9582 - val_loss: 0.2862 - val_acc: 0.9275\n",
      "Epoch 42/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1457 - acc: 0.9527 - val_loss: 0.2768 - val_acc: 0.9348\n",
      "Epoch 43/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1401 - acc: 0.9564 - val_loss: 0.2947 - val_acc: 0.9203\n",
      "Epoch 44/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1425 - acc: 0.9564 - val_loss: 0.2840 - val_acc: 0.9420\n",
      "Epoch 45/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1445 - acc: 0.9545 - val_loss: 0.2719 - val_acc: 0.9420\n",
      "Epoch 46/100\n",
      "550/550 [==============================] - ETA: 0s - loss: 0.1402 - acc: 0.957 - 1s 2ms/step - loss: 0.1391 - acc: 0.9582 - val_loss: 0.2788 - val_acc: 0.9275\n",
      "Epoch 47/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1456 - acc: 0.9527 - val_loss: 0.2739 - val_acc: 0.9275\n",
      "Epoch 48/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1435 - acc: 0.9582 - val_loss: 0.2838 - val_acc: 0.9275\n",
      "Epoch 49/100\n",
      "550/550 [==============================] - 1s 3ms/step - loss: 0.1336 - acc: 0.9618 - val_loss: 0.3134 - val_acc: 0.9058\n",
      "Epoch 50/100\n",
      "550/550 [==============================] - 2s 3ms/step - loss: 0.1365 - acc: 0.9600 - val_loss: 0.2740 - val_acc: 0.9420\n",
      "Epoch 51/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1387 - acc: 0.9600 - val_loss: 0.2693 - val_acc: 0.9348\n",
      "Epoch 52/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1441 - acc: 0.9655 - val_loss: 0.2714 - val_acc: 0.9348\n",
      "Epoch 53/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1381 - acc: 0.9564 - val_loss: 0.2681 - val_acc: 0.9420\n",
      "Epoch 54/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1425 - acc: 0.9600 - val_loss: 0.2714 - val_acc: 0.9348\n",
      "Epoch 55/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1416 - acc: 0.9582 - val_loss: 0.2781 - val_acc: 0.9348\n",
      "Epoch 56/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1415 - acc: 0.9636 - val_loss: 0.2860 - val_acc: 0.9420\n",
      "Epoch 57/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1380 - acc: 0.9582 - val_loss: 0.2883 - val_acc: 0.9203\n",
      "Epoch 58/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1521 - acc: 0.9564 - val_loss: 0.2884 - val_acc: 0.9275\n",
      "Epoch 59/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1524 - acc: 0.9564 - val_loss: 0.2923 - val_acc: 0.9203\n",
      "Epoch 60/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1522 - acc: 0.9564 - val_loss: 0.2847 - val_acc: 0.9275\n",
      "Epoch 61/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1365 - acc: 0.9564 - val_loss: 0.3124 - val_acc: 0.9275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1555 - acc: 0.9600 - val_loss: 0.2923 - val_acc: 0.9348\n",
      "Epoch 63/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1487 - acc: 0.9564 - val_loss: 0.2808 - val_acc: 0.9493\n",
      "Epoch 64/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1470 - acc: 0.9582 - val_loss: 0.2822 - val_acc: 0.9348\n",
      "Epoch 65/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1502 - acc: 0.9545 - val_loss: 0.2878 - val_acc: 0.9275\n",
      "Epoch 66/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1444 - acc: 0.9564 - val_loss: 0.2891 - val_acc: 0.9203\n",
      "Epoch 67/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1442 - acc: 0.9545 - val_loss: 0.2843 - val_acc: 0.9348\n",
      "Epoch 68/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1427 - acc: 0.9600 - val_loss: 0.2826 - val_acc: 0.9420\n",
      "Epoch 69/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1457 - acc: 0.9600 - val_loss: 0.2874 - val_acc: 0.9420\n",
      "Epoch 70/100\n",
      "550/550 [==============================] - 2s 3ms/step - loss: 0.1492 - acc: 0.9564 - val_loss: 0.2854 - val_acc: 0.9348\n",
      "Epoch 71/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1379 - acc: 0.9564 - val_loss: 0.2959 - val_acc: 0.9420\n",
      "Epoch 72/100\n",
      "550/550 [==============================] - 2s 3ms/step - loss: 0.1526 - acc: 0.9600 - val_loss: 0.2943 - val_acc: 0.9348\n",
      "Epoch 73/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1487 - acc: 0.9600 - val_loss: 0.3010 - val_acc: 0.9348\n",
      "Epoch 74/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1462 - acc: 0.9582 - val_loss: 0.2983 - val_acc: 0.9420\n",
      "Epoch 75/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1535 - acc: 0.9618 - val_loss: 0.3024 - val_acc: 0.9275\n",
      "Epoch 76/100\n",
      "550/550 [==============================] - 1s 3ms/step - loss: 0.1491 - acc: 0.9582 - val_loss: 0.3050 - val_acc: 0.9058\n",
      "Epoch 77/100\n",
      "550/550 [==============================] - 1s 3ms/step - loss: 0.1540 - acc: 0.9564 - val_loss: 0.3202 - val_acc: 0.8986\n",
      "Epoch 78/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1487 - acc: 0.9600 - val_loss: 0.3070 - val_acc: 0.9203\n",
      "Epoch 79/100\n",
      "550/550 [==============================] - 1s 3ms/step - loss: 0.1498 - acc: 0.9600 - val_loss: 0.2978 - val_acc: 0.9420\n",
      "Epoch 80/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1530 - acc: 0.9618 - val_loss: 0.2938 - val_acc: 0.9203\n",
      "Epoch 81/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1408 - acc: 0.9582 - val_loss: 0.2974 - val_acc: 0.9275\n",
      "Epoch 82/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1478 - acc: 0.9564 - val_loss: 0.2893 - val_acc: 0.9203\n",
      "Epoch 83/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1496 - acc: 0.9582 - val_loss: 0.2856 - val_acc: 0.9203\n",
      "Epoch 84/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1481 - acc: 0.9564 - val_loss: 0.3074 - val_acc: 0.9275\n",
      "Epoch 85/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1596 - acc: 0.9545 - val_loss: 0.3028 - val_acc: 0.9203\n",
      "Epoch 86/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1554 - acc: 0.9564 - val_loss: 0.3322 - val_acc: 0.8986\n",
      "Epoch 87/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1522 - acc: 0.9600 - val_loss: 0.2920 - val_acc: 0.9203\n",
      "Epoch 88/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1441 - acc: 0.9600 - val_loss: 0.2939 - val_acc: 0.9275\n",
      "Epoch 89/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1426 - acc: 0.9527 - val_loss: 0.3054 - val_acc: 0.9058\n",
      "Epoch 90/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1510 - acc: 0.9564 - val_loss: 0.2823 - val_acc: 0.9203\n",
      "Epoch 91/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1392 - acc: 0.9582 - val_loss: 0.2964 - val_acc: 0.9420\n",
      "Epoch 92/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1481 - acc: 0.9527 - val_loss: 0.3024 - val_acc: 0.9275\n",
      "Epoch 93/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1505 - acc: 0.9618 - val_loss: 0.3003 - val_acc: 0.9275\n",
      "Epoch 94/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1452 - acc: 0.9582 - val_loss: 0.3157 - val_acc: 0.9130\n",
      "Epoch 95/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1421 - acc: 0.9618 - val_loss: 0.3091 - val_acc: 0.9130\n",
      "Epoch 96/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1476 - acc: 0.9600 - val_loss: 0.3165 - val_acc: 0.9058\n",
      "Epoch 97/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1288 - acc: 0.9636 - val_loss: 0.3181 - val_acc: 0.9130\n",
      "Epoch 98/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1443 - acc: 0.9545 - val_loss: 0.3469 - val_acc: 0.9058\n",
      "Epoch 99/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1466 - acc: 0.9582 - val_loss: 0.3443 - val_acc: 0.9058\n",
      "Epoch 100/100\n",
      "550/550 [==============================] - 1s 2ms/step - loss: 0.1446 - acc: 0.9618 - val_loss: 0.3470 - val_acc: 0.9058\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_train, partial_l, epochs=100, batch_size=1, validation_data=(val_train, val_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5615dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, loss, 'ro', label='Train loss')\n",
    "plt.plot(epochs, val_loss, 'g-', label='Validation loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17b7a0",
   "metadata": {},
   "source": [
    "###  Final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a57f8f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "688/688 [==============================] - 1s 1ms/step - loss: 0.5679 - acc: 0.7224\n",
      "Epoch 2/10\n",
      "688/688 [==============================] - 1s 1ms/step - loss: 0.3495 - acc: 0.9055\n",
      "Epoch 3/10\n",
      "688/688 [==============================] - 1s 2ms/step - loss: 0.2522 - acc: 0.9142\n",
      "Epoch 4/10\n",
      "688/688 [==============================] - 1s 2ms/step - loss: 0.2188 - acc: 0.9346\n",
      "Epoch 5/10\n",
      "688/688 [==============================] - 1s 2ms/step - loss: 0.1991 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "688/688 [==============================] - 1s 2ms/step - loss: 0.1870 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "688/688 [==============================] - 1s 2ms/step - loss: 0.1835 - acc: 0.9419\n",
      "Epoch 8/10\n",
      "688/688 [==============================] - 1s 1ms/step - loss: 0.1816 - acc: 0.9419\n",
      "Epoch 9/10\n",
      "688/688 [==============================] - 1s 1ms/step - loss: 0.1727 - acc: 0.9404\n",
      "Epoch 10/10\n",
      "688/688 [==============================] - 1s 1ms/step - loss: 0.1635 - acc: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14169d26220>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(6, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics='acc')\n",
    "model.fit(train_data, train_l, epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e61f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.1767 - acc: 0.9426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17672230303287506, 0.9425675868988037]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67d2dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred  = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f14ecfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.00881287],\n",
       "       [0.00692943],\n",
       "       [0.00977576],\n",
       "       [0.01647919]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "efd250a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_l[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
